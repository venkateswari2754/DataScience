{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import ast\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import pickle\n",
        "import nltk\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "import requests\n",
        "\n",
        "\n",
        "# Convert 'genres' and 'keywords' to lists of strings\n",
        "def convert(obj):\n",
        "    list_ = []\n",
        "    for i in ast.literal_eval(obj):\n",
        "        list_.append(i['name'])\n",
        "    return list_\n",
        "\n",
        "# Extract top 3 cast members\n",
        "def get_top_three(obj):\n",
        "    list_ = []\n",
        "    counter = 0\n",
        "    for i in ast.literal_eval(obj):\n",
        "        if counter != 3:\n",
        "            list_.append(i['name'])\n",
        "            counter += 1\n",
        "        else:\n",
        "            break\n",
        "    return list_\n",
        "\n",
        "# Extract director from 'crew'\n",
        "def fetch_director(crew_data):\n",
        "    directorlist_ = []\n",
        "    crew_list = ast.literal_eval(crew_data)\n",
        "    for crew_member in crew_list:\n",
        "        if crew_member.get('job') == 'Director':\n",
        "            directorlist_.append(crew_member.get('name'))\n",
        "    return directorlist_\n",
        "\n",
        "#Stemming function\n",
        "ps=PorterStemmer()\n",
        "def stem(text):\n",
        "  y=[]\n",
        "  for i in text.split():\n",
        "    y.append(ps.stem(i))\n",
        "  return \" \".join(y)\n",
        "\n",
        "\n",
        "# Load the movies and credits data\n",
        "movies = pd.read_csv('/content/sample_data/tmdb_5000_credits.csv')\n",
        "credits = pd.read_csv('/content/sample_data/tmdb_5000_movies.csv')\n",
        "\n",
        "# Merge the two DataFrames\n",
        "movies = movies.merge(credits, on='title')\n",
        "\n",
        "# Select the desired columns\n",
        "movies = movies[['movie_id', 'title', 'overview', 'genres', 'keywords', 'cast', 'crew']]\n",
        "\n",
        "# Handle missing values and duplicates\n",
        "movies.dropna(inplace=True)\n",
        "movies.drop_duplicates(inplace=True)\n",
        "\n",
        "movies['genres'] = movies['genres'].apply(convert)\n",
        "movies['keywords'] = movies['keywords'].apply(convert)\n",
        "\n",
        "#get top three\n",
        "movies['cast'] = movies['cast'].apply(get_top_three)\n",
        "\n",
        "#fetch only directors\n",
        "movies['crew'] = movies['crew'].apply(fetch_director)\n",
        "\n",
        "# Convert 'overview' to list of words\n",
        "movies['overview'] = movies['overview'].apply(lambda x: x.split())\n",
        "\n",
        "# Remove spaces from 'genres', 'keywords', 'cast', and 'crew'\n",
        "movies['genres'] = movies['genres'].apply(lambda x: [i.replace(\" \", \"\") for i in x])\n",
        "movies['keywords'] = movies['keywords'].apply(lambda x: [i.replace(\" \", \"\") for i in x])\n",
        "movies['cast'] = movies['cast'].apply(lambda x: [i.replace(\" \", \"\") for i in x])\n",
        "movies['crew'] = movies['crew'].apply(lambda x: [i.replace(\" \", \"\") for i in x])\n",
        "\n",
        "#concat all the columns into one tag\n",
        "movies['tags'] = movies['overview'] + movies['genres'] + movies['keywords'] + movies['cast'] + movies['crew']\n",
        "\n",
        "#create new dataframe\n",
        "new_df = movies[['movie_id', 'title', 'tags']]\n",
        "\n",
        "# Convert tags into string and each list should concat with space\n",
        "new_df['tags'] = new_df['tags'].apply(lambda x: \" \".join(x))\n",
        "\n",
        "# Convert tags into lowercase\n",
        "new_df['tags'] = new_df['tags'].apply(lambda x: x.lower())\n",
        "\n",
        "#let's implement vectorization. The user provide movie based on that 5 similar movies should be provided\n",
        "cv=CountVectorizer(max_features=5000,stop_words='english')\n",
        "\n",
        "#sykit send the data in the form of matrix, need to convert into numpy array\n",
        "vectors=cv.fit_transform(new_df['tags']).toarray()\n",
        "\n",
        "# apply stemming as to substitue same words like loved, loving, love\n",
        "new_df['tags']=new_df['tags'].apply(stem)\n",
        "\n",
        "#Let's caliculate the distance between the movies. if distance is more similarity will be more.\n",
        "#it shows similarity with other movies\n",
        "similarity=cosine_similarity(vectors)\n",
        "\n",
        "def recommend(movie):\n",
        "    # Convert movie title to lowercase for case-insensitive matching\n",
        "    movie = movie.lower()\n",
        "    movie_index = new_df[new_df['title'].str.lower() == movie].index\n",
        "    if len(movie_index) > 0:  # Check if any matching movies were found\n",
        "        movie_index = movie_index[0]\n",
        "        distances = similarity[movie_index]\n",
        "        movies_list = sorted(list(enumerate(distances)), reverse=True, key=lambda x: x[1])[1:6]\n",
        "        recommended_movies_poster = []\n",
        "        recommended_movies = []\n",
        "        for i in movies_list:\n",
        "            recommended_movies.append(new_df.iloc[i[0]].title)\n",
        "            recommended_movies_poster.append(new_df.iloc[i[0]].movie_id)\n",
        "        return recommended_movies,recommended_movies_poster\n",
        "    else:\n",
        "        return \"Movie not found in the dataset.\" #Return a message if movie is not found\n",
        "\n",
        "def fetch_poster(movie_id):\n",
        "    response = requests.get('https://api.themoviedb.org/3/movie/{}?api_key=8265&language=en-US'.format(movie_id))\n",
        "    data = response.json()\n",
        "    return \"https://image.tmdb.org/t/p/w500/\" + data['poster_path']\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "0kJ4YOl2pA-q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "recommend('avatar')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RmDaydcYoJWY",
        "outputId": "ccdd1565-58f2-4cf0-ba05-d91a55f69a2b"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['Titan A.E.',\n",
              "  'Small Soldiers',\n",
              "  \"Ender's Game\",\n",
              "  'Aliens vs Predator: Requiem',\n",
              "  'Independence Day'],\n",
              " [7450, 11551, 80274, 440, 602])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "pickle.dump(new_df,open('movies.pkl','wb'))"
      ],
      "metadata": {
        "id": "kX1loA5YfY8y"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install streamlit\n"
      ],
      "metadata": {
        "id": "dngQRqwAgSm5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install ffmpeg"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V_fXIV6owxO6",
        "outputId": "d55c33a8-0126-4ec4-a686-1df587a06847"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 29 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyngrok"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DaMgsVUVsF4h",
        "outputId": "7f90b1dc-7260-4ba2-f077-de12f6b1ab55"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyngrok\n",
            "  Downloading pyngrok-7.2.3-py3-none-any.whl.metadata (8.7 kB)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.11/dist-packages (from pyngrok) (6.0.2)\n",
            "Downloading pyngrok-7.2.3-py3-none-any.whl (23 kB)\n",
            "Installing collected packages: pyngrok\n",
            "Successfully installed pyngrok-7.2.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "import pickle\n",
        "st.title('Movie Recommender System')\n",
        "movies_list=pickle.load(open('movies.pkl','rb'))\n",
        "movies_list=movies_list['title'].values\n",
        "selected_movie=st.selectbox(\n",
        "    \"Type or select a movie from the dropdown\",\n",
        "    movies_list\n",
        ")\n",
        "if st.button('Show Recommendation'):\n",
        "  names,poster=recommend(selected_movie)\n",
        "  col1,col2,col3,col4,col5=st.columns(5)\n",
        "  with col1:\n",
        "    st.text(names[0])\n",
        "    st.image(fetch_poster(poster[0]))\n",
        "  with col2:\n",
        "    st.text(names[1])\n",
        "    st.image(fetch_poster(poster[1]))\n",
        "  with col3:\n",
        "    st.text(names[2])\n",
        "    st.image(fetch_poster(poster[2]))\n",
        "  with col4:\n",
        "    st.text(names[3])\n",
        "    st.image(fetch_poster(poster[3]))\n",
        "  with col5:\n",
        "    st.text(names[4])\n",
        "    st.image(fetch_poster(poster[4]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J8DdUALbslth",
        "outputId": "425b00d6-c924-4fc3-87c0-d301fa86c8c0"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!streamlit run app.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2JUHQIgusn1Y",
        "outputId": "048f36a2-44f1-46be-ab2b-ee2742fa5e0f"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
            "\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://35.229.82.177:8501\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Stopping...\u001b[0m\n",
            "\u001b[34m  Stopping...\u001b[0m\n"
          ]
        }
      ]
    }
  ]
}