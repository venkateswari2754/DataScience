{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import ast\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import pickle\n",
        "import nltk\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "\n",
        "\n",
        "# Convert 'genres' and 'keywords' to lists of strings\n",
        "def convert(obj):\n",
        "    list_ = []\n",
        "    for i in ast.literal_eval(obj):\n",
        "        list_.append(i['name'])\n",
        "    return list_\n",
        "\n",
        "# Extract top 3 cast members\n",
        "def get_top_three(obj):\n",
        "    list_ = []\n",
        "    counter = 0\n",
        "    for i in ast.literal_eval(obj):\n",
        "        if counter != 3:\n",
        "            list_.append(i['name'])\n",
        "            counter += 1\n",
        "        else:\n",
        "            break\n",
        "    return list_\n",
        "\n",
        "# Extract director from 'crew'\n",
        "def fetch_director(crew_data):\n",
        "    directorlist_ = []\n",
        "    crew_list = ast.literal_eval(crew_data)\n",
        "    for crew_member in crew_list:\n",
        "        if crew_member.get('job') == 'Director':\n",
        "            directorlist_.append(crew_member.get('name'))\n",
        "    return directorlist_\n",
        "\n",
        "#Stemming function\n",
        "ps=PorterStemmer()\n",
        "def stem(text):\n",
        "  y=[]\n",
        "  for i in text.split():\n",
        "    y.append(ps.stem(i))\n",
        "  return \" \".join(y)\n",
        "\n",
        "\n",
        "# Load the movies and credits data\n",
        "movies = pd.read_csv('/content/sample_data/tmdb_5000_credits.csv')\n",
        "credits = pd.read_csv('/content/sample_data/tmdb_5000_movies.csv')\n",
        "\n",
        "# Merge the two DataFrames\n",
        "movies = movies.merge(credits, on='title')\n",
        "\n",
        "# Select the desired columns\n",
        "movies = movies[['movie_id', 'title', 'overview', 'genres', 'keywords', 'cast', 'crew']]\n",
        "\n",
        "# Handle missing values and duplicates\n",
        "movies.dropna(inplace=True)\n",
        "movies.drop_duplicates(inplace=True)\n",
        "\n",
        "movies['genres'] = movies['genres'].apply(convert)\n",
        "movies['keywords'] = movies['keywords'].apply(convert)\n",
        "\n",
        "#get top three\n",
        "movies['cast'] = movies['cast'].apply(get_top_three)\n",
        "\n",
        "#fetch only directors\n",
        "movies['crew'] = movies['crew'].apply(fetch_director)\n",
        "\n",
        "# Convert 'overview' to list of words\n",
        "movies['overview'] = movies['overview'].apply(lambda x: x.split())\n",
        "\n",
        "# Remove spaces from 'genres', 'keywords', 'cast', and 'crew'\n",
        "movies['genres'] = movies['genres'].apply(lambda x: [i.replace(\" \", \"\") for i in x])\n",
        "movies['keywords'] = movies['keywords'].apply(lambda x: [i.replace(\" \", \"\") for i in x])\n",
        "movies['cast'] = movies['cast'].apply(lambda x: [i.replace(\" \", \"\") for i in x])\n",
        "movies['crew'] = movies['crew'].apply(lambda x: [i.replace(\" \", \"\") for i in x])\n",
        "\n",
        "#concat all the columns into one tag\n",
        "movies['tags'] = movies['overview'] + movies['genres'] + movies['keywords'] + movies['cast'] + movies['crew']\n",
        "\n",
        "#create new dataframe\n",
        "new_df = movies[['movie_id', 'title', 'tags']]\n",
        "\n",
        "# Convert tags into string and each list should concat with space\n",
        "new_df['tags'] = new_df['tags'].apply(lambda x: \" \".join(x))\n",
        "\n",
        "# Convert tags into lowercase\n",
        "new_df['tags'] = new_df['tags'].apply(lambda x: x.lower())\n",
        "\n",
        "#let's implement vectorization. The user provide movie based on that 5 similar movies should be provided\n",
        "cv=CountVectorizer(max_features=5000,stop_words='english')\n",
        "\n",
        "#sykit send the data in the form of matrix, need to convert into numpy array\n",
        "vectors=cv.fit_transform(new_df['tags']).toarray()\n",
        "\n",
        "# apply stemming as to substitue same words like loved, loving, love\n",
        "new_df['tags']=new_df['tags'].apply(stem)\n",
        "\n",
        "#Let's caliculate the distance between the movies. if distance is more similarity will be more.\n",
        "#it shows similarity with other movies\n",
        "similarity=cosine_similarity(vectors)\n",
        "\n",
        "def recommend(movie):\n",
        "    # Convert movie title to lowercase for case-insensitive matching\n",
        "    movie = movie.lower()\n",
        "    movie_index = new_df[new_df['title'].str.lower() == movie].index\n",
        "    if len(movie_index) > 0:  # Check if any matching movies were found\n",
        "        movie_index = movie_index[0]\n",
        "        distances = similarity[movie_index]\n",
        "        movies_list = sorted(list(enumerate(distances)), reverse=True, key=lambda x: x[1])[1:6]\n",
        "\n",
        "        recommended_movies = []\n",
        "        for i in movies_list:\n",
        "            recommended_movies.append(new_df.iloc[i[0]].title)\n",
        "        return recommended_movies\n",
        "    else:\n",
        "        return \"Movie not found in the dataset.\" #Return a message if movie is not found\n"
      ],
      "metadata": {
        "id": "0kJ4YOl2pA-q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "recommend('avatar')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BLlRg11H0eWq",
        "outputId": "c1e7de1a-01df-4e47-8134-9d9b752e4773"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Titan A.E.',\n",
              " 'Small Soldiers',\n",
              " \"Ender's Game\",\n",
              " 'Aliens vs Predator: Requiem',\n",
              " 'Independence Day']"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    }
  ]
}
